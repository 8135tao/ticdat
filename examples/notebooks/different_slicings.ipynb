{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing with pandas, gurobipy.tuplelist, and O(n) slicing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run a little python script that sets up the performance comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "run prep_for_different_slicings.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The slicing will be over small, medium, and large tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1200, 31800, 270000]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(getattr(td, \"childTable\")) for td in (smallTd, medTd, bigTd)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will run three series of three tests each.\n",
    "\n",
    "Each series tests (1) slicing with `.sloc` and `pandas`, (2) slicing with `gurobipy.tuplelist` (3) O(n) slicing \n",
    "\n",
    "First, we see that with a small table (1,200) rows, the `pandas` slicing is only somewhat faster than the O(n) slicing, while the `tuplelist` slicing is quite a bit faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 loops, best of 3: 1.6 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit checkChildDfLen(smallChildDf, *smallChk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 loops, best of 3: 5.17 us per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit checkTupleListLen(smallSmartTupleList, *smallChk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 5.85 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit checkTupleListLen(smallDumbTupleList, *smallChk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we see that with a table of 31,800 rows, `pandas` slicing is now ~100 faster than O(n) slicing (but `tuplelist` is still the fastest by far)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 loops, best of 3: 2.04 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit checkChildDfLen(medChildDf, *medChk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 loops, best of 3: 5.43 us per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit checkTupleListLen(medSmartTupleList, *medChk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 3: 183 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit checkTupleListLen(medDumbTupleList, *medChk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we see that with a table of 270,000 rows, `pandas` slicing is ~1000X faster than O(n) slicing (which is comparable to the improvement `tuplelist` shows over `.sloc`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 4.49 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit checkChildDfLen(bigChildDf, *bigChk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 loops, best of 3: 5.51 us per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit checkTupleListLen(bigSmartTupleList, *bigChk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 3: 1.53 s per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit checkTupleListLen(bigDumbTupleList, *bigChk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bottom line? `pandas` isn't really designed with \"iterating over indicies and slicing\" in mind, so it isn't the absolutely fastest way to write this sort of code. However, `pandas` also doesn't implement naive O(n) slicing. \n",
    "\n",
    "For most instances, the `.sloc` approach to slicing will be fast enough. In general, so long as you use the optimal big-O subroutines, the time to solve a MIP or LP model will be larger than the time to formulate the model.  However, in those instances where the slicing is the bottleneck operation, a `tuplelist` can be used, or the model building code can be refactored to be more pandonic.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Addendum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There was a request to check `sum` as well as `len`. Here you go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 4.71 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit checkChildDfSum(bigChildDf, *bigChk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 3.37 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit checkTupleListSum(bigSmartTupleList, bigTd, *bigChk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 3: 1.51 s per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit checkTupleListSum(bigDumbTupleList, bigTd, *bigChk)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
